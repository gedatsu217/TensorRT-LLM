Inside docker
/TensorRT-LLM/examples/llama /home/gedatsu/TensorRT-LLM/examples/llama
Runing mpirun -n 4 --allow-run-as-root python3 run.py --input_tokens ./inputs/input_16.csv --max_output_len 1 --tokenizer_dir meta-llama/Llama-2-7b-hf --engine_dir=./tmp/llama/7B/trt_engines/fp16/4-gpu/
Running the float16 engine ...
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Input: "<s>The capital of China is"
Output: "Be"
Time: 39.841615 ms
Time: 77.020974 ms
Time: 22.233403 ms
Time: 42.330306 ms
/home/gedatsu/TensorRT-LLM/examples/llama
