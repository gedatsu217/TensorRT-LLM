Inside docker
/TensorRT-LLM/examples/llama /home/gedatsu/TensorRT-LLM/examples/llama
Runing python3 run.py --input_tokens ./inputs/input_1.csv --max_output_len 1 --tokenizer_dir meta-llama/Llama-2-13b-hf --engine_dir=./tmp/llama/7B/trt_engines/fp16/4-gpu/
[Manifold] Controller instance created for 4 gpus
[Manifold] Adding a worker with tid: 0
[Manifold] Adding a worker with tid: 1
[Manifold] Adding a worker with tid: 2
[Manifold] Adding a worker with tid: 3
tid:  2 gpu_id:  2
tid:  0 gpu_id:  0
tid:  3 gpu_id:  3
tid:  1 gpu_id:  1
Running the float16 engine ...
Input: "<s>The capital of China is"
Output: "a"
Time: 30.261747 ms
Time: 30.078937 ms
Time: 30.236275 ms
Time: 30.440281 ms
[Manifold] All workers joined!
[Controller] Instance destroyed
/home/gedatsu/TensorRT-LLM/examples/llama
Done 1 1